{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anisaAnya/Kaggle_competitions/blob/master/Digit_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "SZT9Gr3BPMjF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "#learn from https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracyport numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "rP2i-6DLPMjV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6GbzNd-EU_5k",
        "colab_type": "code",
        "outputId": "b126f6e6-9204-454f-e258-e122936b1d87",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e15ff43d-7163-4288-a563-16c0d5ad7ded\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e15ff43d-7163-4288-a563-16c0d5ad7ded\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "92c74905-e68d-495b-aec4-fc7b191f6cca",
        "_uuid": "b469dfbd773bc1dba716b5d035fb3c5f379d01dc",
        "trusted": true,
        "id": "v_FtY0RhPMje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "import numbers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5290018a-d49e-44ca-8b42-55278ffd374f",
        "_uuid": "5223c9438c122f5fc9f58ad7606fe17410e83451",
        "trusted": true,
        "id": "2-GxjdvUPMjo",
        "colab_type": "code",
        "outputId": "93a9ad66-a478-47a2-a6be-14cf237662a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "6370c608-b8ef-416b-97c1-c7cac8b0cc89",
        "_uuid": "f6555d50e3525108b25a5a54394dfb60e6bb0488",
        "trusted": true,
        "id": "ZTve8cThPMjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class mydata(Dataset):\n",
        "     def __init__(self, file_path, \n",
        "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
        "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "                ):\n",
        "        \n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        if len(df.columns) == n_pixels:\n",
        "            # test data\n",
        "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = None\n",
        "        else:\n",
        "            # training data\n",
        "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
        "            \n",
        "        self.transform = transform\n",
        "    \n",
        "     def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "     def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.transform(self.X[idx]), self.y[idx]\n",
        "        else:\n",
        "            return self.transform(self.X[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "72328c50-4cf3-496e-99fb-c3e337f8e4ba",
        "_uuid": "4c45a79132c757c2c6ff7b210f9f1316b3e99857",
        "trusted": true,
        "id": "0kbPda70PMj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomShift(object):\n",
        "    def __init__(self, shift):\n",
        "        self.shift = shift\n",
        "        \n",
        "    @staticmethod\n",
        "    def get_params(shift):\n",
        "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
        "        Returns:\n",
        "            sequence: params to be passed to ``rotate`` for random rotation.\n",
        "        \"\"\"\n",
        "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
        "\n",
        "        return hshift, vshift \n",
        "    def __call__(self, img):\n",
        "        hshift, vshift = self.get_params(self.shift)\n",
        "        \n",
        "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a094fdab-5edf-4094-8b73-d9533449a4c9",
        "_uuid": "2d9c20c936a8c900e69fb3038d1ba96da30174e6",
        "trusted": true,
        "id": "baAls6jVPMkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_test = len(test_df)\n",
        "n_pixels = len(test_df.columns)\n",
        "train_dataset = mydata('train.csv', transform= transforms.Compose(\n",
        "                            [transforms.ToPILImage(),transforms.RandomRotation(degrees=40), RandomShift(4),\n",
        "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
        "test_dataset = mydata('test.csv', )\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugjYgj8ClurB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
        "        return x.view(-1, shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liQy7237ncW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Dense(nn.Module):\n",
        "\n",
        "    def __init__(self,input_n,out_n):\n",
        "        super(Dense, self).__init__()\n",
        "\n",
        "        # Inputs = 5, Outputs = 3, Hidden = 30\n",
        "        self.fc1 = nn.Linear(input_n, 128)\n",
        "        self.fc2 = nn.Linear(128, out_n)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        outputs = self.fc2(x)\n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aaa450695b0970d8d70a4fb8331ca8da68003d9c",
        "id": "0I0Z8cyYPMkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        main = nn.Sequential()\n",
        "        main.add_module('Flatten', Flatten())\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p = 0.25),\n",
        "            \n",
        "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p = 0.25),\n",
        "            \n",
        "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(p = 0.25),\n",
        "            \n",
        "        )\n",
        "          \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.Linear(1600, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.Dropout(p = 0.25),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e4d63e8e-3ae8-47ad-9101-edc73f7ee3db",
        "_uuid": "9f2da3daf0154546e61f6888a50308419892c909",
        "trusted": true,
        "id": "WiumIbfCPMkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ce82d87f65b4d4856cd91341ba47e754b685989",
        "id": "wr39CMDIPMkm",
        "colab_type": "code",
        "outputId": "75cd5540-7d7e-4946-f3de-14c4ca4f3075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Dropout(p=0.25)\n",
            "    (8): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (12): ReLU(inplace)\n",
            "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Dropout(p=0.25)\n",
            "    (16): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): Dropout(p=0.25)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.25)\n",
            "    (1): Linear(in_features=1600, out_features=512, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Dropout(p=0.25)\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): Dropout(p=0.25)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "3f49ec25-977e-49e1-a712-d630a4871533",
        "_uuid": "2e044f0ab05eb7dd331d701cca497b70858d6045",
        "trusted": true,
        "id": "6F7zDM_fPMkr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    exp_lr_scheduler.step()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(loss.data)\n",
        "        \n",
        "        if (batch_idx + 1)% 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                100. * (batch_idx + 1) / len(train_loader),\n",
        "                loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fa24669e-01e8-4e65-957b-b108b442c5de",
        "_uuid": "3bd36696a25e0c0a55326124eebe572f569108da",
        "trusted": true,
        "id": "aK6ZmVjzPMkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for data, target in data_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        \n",
        "        loss += F.cross_entropy(output, target, size_average=False).item() \n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(data_loader.dataset)\n",
        "        \n",
        "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "       loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6699ff22-84a3-499d-8179-71bb7dd19a62",
        "_uuid": "449cf81040defb0da0cf78af21b1b56fb871906e",
        "trusted": true,
        "id": "DPtelrqGPMk6",
        "colab_type": "code",
        "outputId": "19ab99ea-5c58-48b6-ab81-c1b94cb847c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)\n",
        "    evaluate(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.787041\n",
            "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.689215\n",
            "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.757866\n",
            "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.434492\n",
            "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.535299\n",
            "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.605747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average loss: 0.1755, Accuracy: 39822/42000 (94.000%)\n",
            "\n",
            "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.523207\n",
            "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.288132\n",
            "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.356521\n",
            "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.362271\n",
            "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.466572\n",
            "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.447510\n",
            "\n",
            "Average loss: 0.1139, Accuracy: 40649/42000 (96.000%)\n",
            "\n",
            "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.203960\n",
            "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.399571\n",
            "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.324025\n",
            "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.508818\n",
            "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.307015\n",
            "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.325869\n",
            "\n",
            "Average loss: 0.0821, Accuracy: 41047/42000 (97.000%)\n",
            "\n",
            "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.249759\n",
            "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.297472\n",
            "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.334838\n",
            "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.308577\n",
            "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.315961\n",
            "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.280280\n",
            "\n",
            "Average loss: 0.0857, Accuracy: 41067/42000 (97.000%)\n",
            "\n",
            "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.312142\n",
            "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.315892\n",
            "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.333023\n",
            "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.340297\n",
            "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.370505\n",
            "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.533477\n",
            "\n",
            "Average loss: 0.0798, Accuracy: 41098/42000 (97.000%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K6AocJncYDll",
        "colab_type": "code",
        "outputId": "8f32939b-808b-4692-bcae-2cbdc158f366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1201
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.000003)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.005)\n",
        "\n",
        "n_epochs = 7\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)\n",
        "    evaluate(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.351474\n",
            "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.314276\n",
            "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.293155\n",
            "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.408353\n",
            "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.481477\n",
            "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.227153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average loss: 0.0656, Accuracy: 41270/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.268242\n",
            "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.175407\n",
            "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.388101\n",
            "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.351373\n",
            "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.358885\n",
            "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.322900\n",
            "\n",
            "Average loss: 0.0603, Accuracy: 41290/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.270314\n",
            "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.383709\n",
            "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.563525\n",
            "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.394895\n",
            "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.165169\n",
            "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.384146\n",
            "\n",
            "Average loss: 0.0607, Accuracy: 41284/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.409781\n",
            "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.456798\n",
            "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.375175\n",
            "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.373437\n",
            "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.401705\n",
            "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.386450\n",
            "\n",
            "Average loss: 0.0601, Accuracy: 41307/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.597514\n",
            "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.305671\n",
            "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.315847\n",
            "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.334699\n",
            "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.350650\n",
            "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.263642\n",
            "\n",
            "Average loss: 0.0588, Accuracy: 41313/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.264367\n",
            "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.593075\n",
            "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.414998\n",
            "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.525622\n",
            "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.191280\n",
            "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.246501\n",
            "\n",
            "Average loss: 0.0617, Accuracy: 41293/42000 (98.000%)\n",
            "\n",
            "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.209802\n",
            "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.334031\n",
            "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.344585\n",
            "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.419397\n",
            "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.276967\n",
            "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.529189\n",
            "\n",
            "Average loss: 0.0626, Accuracy: 41313/42000 (98.000%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0f33df49-92f1-4356-9451-4a0c8c4b8d15",
        "_uuid": "0bd76e85a92cd4953c9692e242e2312c7a14ddc7",
        "trusted": true,
        "id": "bcseMkrZPMlG",
        "colab_type": "code",
        "outputId": "720a394c-ed08-4fbe-fb0d-8180d7603df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "def prediciton(data_loader):\n",
        "    model.eval()\n",
        "    test_pred = torch.LongTensor()\n",
        "    \n",
        "    for i, data in enumerate(data_loader):\n",
        "        data = Variable(data, volatile=True)\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            \n",
        "        output = model(data)\n",
        "        \n",
        "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
        "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
        "        \n",
        "    return test_pred\n",
        "test_pred = prediciton(test_loader)\n",
        "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
        "                      columns=['ImageId', 'Label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ff865829-6546-4282-90d4-8b6d496fba89",
        "_uuid": "d727aa7f49cd15c99f0e0b1dc4a6d8819dc411e4",
        "trusted": true,
        "id": "21yUos4OPMlK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv('submission111.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9d419ec6-1205-40a6-a5d0-9506110e00d1",
        "_uuid": "87298364d6915ce3402c06adde69738f8bdee60f",
        "trusted": true,
        "id": "N3mSp7RlPMlR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}